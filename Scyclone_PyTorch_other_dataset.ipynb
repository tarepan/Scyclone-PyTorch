{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Scyclone_PyTorch.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyP/57GmZrJOovlPnD3wcF+A"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"source":["# Scyclone-PyTorch / your Dataset\n","[![Generic badge](https://img.shields.io/badge/GitHub-Scyclone--PyTorch-9cf.svg)][github]\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook]\n","[![Paper](http://img.shields.io/badge/paper-arxiv.2005.03334-B31B1B.svg)][paper]  \n","\n","Reimplmentation of voice conversion system \"Scyclone\" with PyTorch  \n","Author: [tarepan](https://github.com/tarepan)\n","\n","[github]:https://github.com/tarepan/Scyclone-PyTorch\n","[paper]:https://arxiv.org/abs/2005.03334\n","[notebook]:https://colab.research.google.com/github/tarepan/Scyclone-PyTorch/blob/main/Scyclone_PyTorch.ipynb"],"cell_type":"markdown","metadata":{}},{"cell_type":"markdown","metadata":{"id":"QFQivUIyZyYi"},"source":["## Colab Check\n","Check\n","- Google Colaboratory runnning time\n","- GPU type\n","- Python version\n","- CUDA version"]},{"cell_type":"code","metadata":{"id":"4cwyMoXOZ7e1"},"source":["!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'\n","!head -n 1 /proc/driver/nvidia/gpus/**/information\n","!cat /usr/local/cuda/version.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K125Ein7VCwM"},"source":["## Setup"]},{"source":["Activate notebook intermittently for long session (RUN once **by hand**)\n","```javascript\n","const refresher = setInterval(()=>{document.querySelector(\"colab-connect-button\").click();console.log(\"clicked for long session\");}, 1000*60*10);\n","```"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"wZ9fU-17Sdxb"},"source":["# repository install\n","!pip uninstall scyclonepytorch -y -q\n","!pip install git+https://github.com/tarepan/Scyclone-PyTorch -q"],"execution_count":null,"outputs":[]},{"source":["## Argument Preparation"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from argparse import ArgumentParser\n","\n","# args\n","arg_strs = [\"--dir_exp\", \".\", \"--max_epochs\", \"400000\"]\n","\n","# parse arguments for Scyclone-Pytorch\n","parser = ArgumentParser()\n","args_scpt = parseArgments(parser, arg_strs)"]},{"source":["## Your Dataset Preparation\n","- Input datum: linear spectrogram (n_fft=254, from 16kHz waveform), described in original paper\n","- Input class: PyTorch-Lightning's `DataModule`\n","\n","You should prepare PyTorch's [`torch.utils.data.dataset.Dataset`][dataset] which yield the spectrogram by yourself.  \n","Below code wrap two (non-parallel) datasets within DataModule.  \n","\n","â€» dataset preparation tips  \n","[`torchaudio.transforms.Spectrogram`][torch_audio_spec] transform wavefrom -> spectrogram.  \n","(Optional Resampling) + `Spectrogram(254)(waveform)` will help you.  \n","[npVCC2016] could be good sample dataset, good lack.  \n","\n","[dataset]:https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n","[torch_audio_spec]:https://pytorch.org/audio/transforms.html#torchaudio.transforms.Spectrogram\n","[npVCC2016]:https://github.com/tarepan/npVCC2016/blob/main/npvcc2016/PyTorch/dataset/spectrogram.py"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import your datasets and set them\n","dataset_A = <your dataset instance>\n","dataset_B = <your dataset instance>\n","n_data_val = <number of validation datum number in dataset>\n","\n","# example\n","from npvcc2016.PyTorch.dataset.spectrogram import NpVCC2016_spec\n","dataset_A = NpVCC2016_spec(root=\".\", train=True, download=True, speakers=[\"SF1\"])\n","dataset_B = NpVCC2016_spec(root=\".\", train=True, download=True, speakers=[\"TM3\"])\n","n_data_val = 8"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NonParallelSpecDataset(Dataset):\n","    \"\"\"Combine two non-parallel datasets as single dataset which yield Tensor Tuple\"\"\"\n","    def __init__(self):\n","        self.datasetA = dataset_A\n","        self.datasetB = dataset_B\n","\n","    def __getitem__(self, n: int):\n","        return (self.datasetA[n], self.datasetB[n])\n","\n","    def __len__(self) -> int:\n","        return min(len(self.datasetA), len(self.datasetB))\n","\n","\n","class NonParallelSpecDataModule(LightningDataModule):\n","    def __init__(\n","        self,\n","        batch_size: int = 64,\n","        performance: DataLoaderPerformance = DataLoaderPerformance(4, True),\n","    ):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self._num_worker = performance.num_workers\n","        self._pin_memory = performance.pin_memory\n","\n","    def prepare_data(self, *args, **kwargs) -> None:\n","        pass\n","\n","    def setup(self, stage=None):\n","        if stage == \"fit\" or stage is None:\n","            dataset_full = NonParallelSpecDataset()\n","            \n","            mod = n_full % self.batch_size\n","            self.dataset_train, self.dataset_val = random_split(\n","                dataset_full, [len(dataset_full) - n_data_val, n_data_val]\n","            )\n","            self.batch_size_val = n_data_val\n","        if stage == \"test\" or stage is None:\n","            self.dataset_test = NonParallelSpecDataset()\n","            self.batch_size_test = self.batch_size\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self._num_worker, pin_memory=self._pin_memory)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.dataset_val, batch_size=self.batch_size_val, num_workers=self._num_worker, pin_memory=self._pin_memory)\n","\n","    def test_dataloader(self):\n","        return DataLoader(self.dataset_test, batch_size=self.batch_size_test, num_workers=self._num_worker, pin_memory=self._pin_memory)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loader_perf = DataLoaderPerformance(\n","    args_scpt.num_workers, not args_scpt.no_pin_memory\n",")\n","\n","# `datamodule` is used for training\n","datamodule = NonParallelSpecDataModule(64, loader_perf)"]},{"source":["## Train"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Start TensorBoard\n","%load_ext tensorboard\n","%tensorboard\n","\n","# Start Training\n","import pytorch_lightning as pl\n","from scyclonepytorch.Scyclone_main import train\n","from scyclonepytorch.args import parseArgments\n","\n","# seed fixation\n","pl.seed_everything(1234)\n","# train\n","train(args_scpt, datamodule)"]}]}